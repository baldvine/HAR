---
title: "Human Activity Recognition"
author: "Baldvin Einarsson"
date: "6/3/2017"
output: 
    html_document:
        keep_md: TRUE

---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment="")
library(knitr)
library(magrittr)
library(caret)
```

Human Activity Recognition (HAR) is an interesting topic, with monitors and sensors becoming widely used. See information on original data in the following website:
[http://groupware.les.inf.puc-rio.br/har](http://groupware.les.inf.puc-rio.br/har)

Here, we look at the weight lifting exercise dataset. This dataset is concerned with classifying whether an a weight lifting exercise was done properly.

# Import Data

Let's download training and test sets from the following websites:

* The data is the following (which will be split into training/test for cross-validation):
[https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)

* The data to predict on:
[https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)

Let's import these data files into `R`, into objects `mainData` and `data2predict`. After a little bit of trial and error, we settle on `na.strings = c("NA","#DIV/0!")` in order to handle missing or invalid values:
```{r loadData, echo=TRUE}
mainData <- read.csv(file = "./data/pml-training.csv",
                     header = TRUE, stringsAsFactors = FALSE, 
                     na.strings = c("NA","#DIV/0!"))

data2predict <- read.csv(file = "./data/pml-testing.csv",
                     header = TRUE, stringsAsFactors = FALSE,
                     na.strings = c("NA","#DIV/0!"))
```

The data contains `r length(mainData)` columns. The columns are the same except for two columns, one from each dataset. The `mainData` contains the column "`r names(mainData)[!(names(mainData) %in% intersect(names(data2predict), names(mainData)))]`" and "`data2predict` contains the column `r names(data2predict)[!(names(data2predict) %in% intersect(names(data2predict), names(mainData)))]`".

Six people performed 10 repetitions of the "Unilateral" Dubbell Biceps Curl", in five different ways. The variable we're interested is called `classe`, and the unique values labeled as A through E, with the following descriptions:

The classes stand for the following:
```{r describeClasses,echo=FALSE}
kable(data.frame(Class=LETTERS[1:5],
                 Description = c("Exactly according to the specification",
                                 "Throwing the elbows to the front",
                                 "Lifting the dumbbell only halfway",
                                 "Lowering the dumbbell only halfway",
                                 "Throwing the hips to the front")
                 )
      )
```

## Remove unwanted columns

We see that the first seven columns are of no use, as they contain line numbers, name of person, time stamps and two columns on "windows". We remove these columns from the `mainData`

```{r}
mainData <- 
    mainData[,-match(c("X","user_name","raw_timestamp_part_1","raw_timestamp_part_2",
                         "cvtd_timestamp","new_window","num_window"),
                     names(mainData))]
```

We also notice that some columns contain only NA values, or a significant amount of NAs. Let's inspect further:
```{r}
countNAs <- sapply(mainData, function(x){sum(is.na(x))})
```
The columns with no NAs are the actual measurements, and they have the following prefixes:
```{r}
regexpr("^[A-Za-z]+", names(countNAs[countNAs == 0])) %>% 
    regmatches(names(countNAs[countNAs == 0]), m = .) %>% 
    unique()
```
The minimum number of NAs in those columns which do have NA values, is `r min(countNAs[countNAs > 0])` (out of `r nrow(mainData))`). These columns are the derived quantities such as max, min, average, variance etc. In fact, all these NA columns have the following prefixes:
```{r}
regexpr("^[A-Za-z]+", names(countNAs[countNAs > 0])) %>% 
    regmatches(names(countNAs[countNAs > 0]), m = .) %>% 
    unique()
```
Let's remove these columns with derived valued and a bunch of NAs:
```{r}
mainData <- mainData[,names(countNAs[countNAs == 0])]
```


Ok, so now all the columns apart the last one (the classifier), are numerical values:
```{r}
sapply(mainData[,-length(mainData)], class) %>% unique
```


This brings us down to `r length(mainData)-1` predictors, all numeric inputs. From now on we expect any predictive algorithm to be able to find important columns, and we stop cleaning the data.

## Split into training and test set

For cross-validation, let's split the data into a training and test set randomly with 60% and 40% of the initial data each, respectively.

```{r}
set.seed(42)
inTrain <- createDataPartition(mainData$classe, p = 0.6)[[1]]
training <- mainData[inTrain,]
test <- mainData[-inTrain,]
```

# Building predictive models

```{r}
modelFitPCA_gbm <- 
  train(classe~., method="gbm", data=training, 
        preProcess = "pca", na.action = na.omit,
        trControl = trainControl(preProcOptions = list(thresh = 0.8)))
training.pred <- predict(object = modelFitPCA_gbm, newdata = training)
test.pred <- predict(object = modelFitPCA_gbm, newdata = test)
confusionMatrix(training.pred, training$classe)
```

